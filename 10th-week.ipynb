{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":7087600,"sourceType":"datasetVersion","datasetId":4083742}],"dockerImageVersionId":30918,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-03-10T05:55:40.753935Z","iopub.execute_input":"2025-03-10T05:55:40.754328Z","iopub.status.idle":"2025-03-10T05:55:40.761810Z","shell.execute_reply.started":"2025-03-10T05:55:40.754299Z","shell.execute_reply":"2025-03-10T05:55:40.760411Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/u-s-census-dataset-education-finance-industry/Educationv.csv\n/kaggle/input/u-s-census-dataset-education-finance-industry/Finance.csv\n/kaggle/input/u-s-census-dataset-education-finance-industry/Industry.csv\n","output_type":"stream"}],"execution_count":69},{"cell_type":"markdown","source":"Step 1: Select a Dataset (10 Marks)\nChoose a dataset from Kaggle or any other open-source platform.\nEnsure the dataset has sufficient features and a well-defined target variable.\n1.(5 Marks): Proper dataset selection (relevant to classification or regression).\n2.(5 Marks): Successfully loading the dataset into Python (Pandas).\n","metadata":{}},{"cell_type":"code","source":"import pandas as pd\n\n# Load dataset\ndf = pd.read_csv('../input/u-s-census-dataset-education-finance-industry/Educationv.csv')\n\n# Display the first few rows\nprint(df.head())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-10T05:55:40.763043Z","iopub.execute_input":"2025-03-10T05:55:40.763403Z","iopub.status.idle":"2025-03-10T05:55:40.793179Z","shell.execute_reply.started":"2025-03-10T05:55:40.763345Z","shell.execute_reply":"2025-03-10T05:55:40.791875Z"}},"outputs":[{"name":"stdout","text":"   Year    cd  Bachelors_degree_or_higher  high_school_or_some_degree  \\\n0  2020  0_AK                      121098                      309698   \n1  2020  0_DC                      277816                      177505   \n2  2020  0_DE                      175338                      351177   \n3  2020  0_ND                      137958                      303148   \n4  2020  0_PR                      121098                      309698   \n\n   Less_than_high_school_graduate  \n0                           33572  \n1                           34652  \n2                           57053  \n3                           26631  \n4                           33572  \n","output_type":"stream"}],"execution_count":70},{"cell_type":"markdown","source":"Step 2: Data Cleaning (20 Marks)\nHandle missing values (remove or impute missing data appropriately).\nCheck for and remove duplicates, if applicable.\nEnsure proper formatting and structure for further analysis.\n1.(10 Marks): Identifying and handling missing values correctly.\n2.(5 Marks): Cleaning data effectively and providing justification.\n3.(5 Marks): Ensuring the dataset is properly structured and ready for modeling","metadata":{}},{"cell_type":"code","source":"# Check for missing values\nprint(df.isnull().sum())\n\n# Remove duplicates if any\ndf.drop_duplicates(inplace=True)\n\n# Check the structure of the dataset\nprint(df.info())\n\n# Ensure proper formatting (e.g., column names, data types)\ndf.columns = df.columns.str.strip()  # Remove any leading/trailing spaces in column names","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-10T05:55:40.816595Z","iopub.status.idle":"2025-03-10T05:55:40.816904Z","shell.execute_reply":"2025-03-10T05:55:40.816781Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Step 3: Exploratory Data Analysis (EDA) & Visualization (20 Marks)\nVisualize important features using graphs (e.g., histograms, scatter plots, bar charts).\nGenerate a correlation heatmap (if applicable).\nExtract and explain 3-5 key insights from the dataset.\n1.(10 Marks): Clear and informative visualizations.\n2.(10 Marks): Well-explained insights based on the visualizations.","metadata":{}},{"cell_type":"code","source":"import seaborn as sns\nimport matplotlib.pyplot as plt\n\n# Set the style for plots\nsns.set(style=\"whitegrid\")\n\n# Histogram for Bachelors_degree_or_higher\nplt.figure(figsize=(8, 6))\nsns.histplot(df['Bachelors_degree_or_higher'], kde=True, bins=30)\nplt.title('Distribution of Bachelors Degree or Higher')\nplt.xlabel('Number of Individuals')\nplt.ylabel('Frequency')\nplt.show()\n\n# Scatter plot: Bachelors_degree_or_higher vs high_school_or_some_degree\nplt.figure(figsize=(8, 6))\nsns.scatterplot(x='high_school_or_some_degree', y='Bachelors_degree_or_higher', data=df)\nplt.title('Bachelors Degree vs High School or Some Degree')\nplt.xlabel('High School or Some Degree')\nplt.ylabel('Bachelors Degree or Higher')\nplt.show()\n\n# Correlation heatmap (exclude the 'cd' column)\nplt.figure(figsize=(10, 8))\nsns.heatmap(df.drop('cd', axis=1).corr(), annot=True, cmap='coolwarm')\nplt.title('Correlation Heatmap')\nplt.show()\n\n# Key Insights\nprint(\"Key Insights:\")\nprint(\"1. The distribution of individuals with a bachelor's degree or higher is right-skewed.\")\nprint(\"2. There is a positive correlation between the number of individuals with a high school degree and those with a bachelor's degree.\")\nprint(\"3. The dataset shows strong correlations between educational attainment levels.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-10T05:55:40.817981Z","iopub.status.idle":"2025-03-10T05:55:40.818244Z","shell.execute_reply":"2025-03-10T05:55:40.818142Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Step 4: Apply a Machine Learning Model (30 Marks)\nChoose and apply either a Regression or Classification model:\nIf the target variable is numerical → Linear Regression.\nIf the target variable is categorical → Logistic Regression or another classification model.\nTrain the model using Scikit-learn.\nDisplay and interpret the accuracy score (for classification) or RMSE (for regression).\n(10 Marks): Correct model selection based on dataset type.\n(10 Marks): Implementing and training the model properly.\n(10 Marks): Displaying and correctly interpreting accuracy/RMSE.\n","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error, r2_score\n\n# Define features (X) and target (y)\nX = df[['high_school_or_some_degree', 'Less_than_high_school_graduate']]\ny = df['Bachelors_degree_or_higher']\n\n# Split the data into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Initialize and train the Linear Regression model\nmodel = LinearRegression()\nmodel.fit(X_train, y_train)\n\n# Make predictions\ny_pred = model.predict(X_test)\n\n# Evaluate the model\nmse = mean_squared_error(y_test, y_pred)\nrmse = mse ** 0.5\nr2 = r2_score(y_test, y_pred)\n\nprint(f\"RMSE: {rmse:.2f}\")\nprint(f\"R2 Score: {r2:.2f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-10T05:55:40.819351Z","iopub.status.idle":"2025-03-10T05:55:40.819612Z","shell.execute_reply":"2025-03-10T05:55:40.819522Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Step 5: Conclusion & Future Improvements (20 Marks)\nSummarize findings and discuss model performance.\nSuggest at least two possible improvements (e.g., using more data, trying a different model, feature engineering).\n(10 Marks): Well-explained summary of findings.\n(10 Marks): Thoughtful suggestions for improvement.\n","metadata":{}},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestRegressor\n\n# Initialize and train the Random Forest Regression model\nrf_model = RandomForestRegressor(n_estimators=100, random_state=42)\nrf_model.fit(X_train, y_train)\n\n# Make predictions\ny_pred_rf = rf_model.predict(X_test)\n\n# Evaluate the model\nmse_rf = mean_squared_error(y_test, y_pred_rf)\nrmse_rf = mse_rf ** 0.5\nr2_rf = r2_score(y_test, y_pred_rf)\n\nprint(f\"Random Forest RMSE: {rmse_rf:.2f}\")\nprint(f\"Random Forest R2 Score: {r2_rf:.2f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-10T05:56:18.121535Z","iopub.execute_input":"2025-03-10T05:56:18.121896Z","iopub.status.idle":"2025-03-10T05:56:18.330236Z","shell.execute_reply.started":"2025-03-10T05:56:18.121865Z","shell.execute_reply":"2025-03-10T05:56:18.328975Z"}},"outputs":[{"name":"stdout","text":"Random Forest RMSE: 69611.99\nRandom Forest R2 Score: 0.23\n","output_type":"stream"}],"execution_count":73}]}